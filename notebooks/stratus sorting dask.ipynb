{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client, progress, metrics\n",
    "# wait for jobs to arrive, depending on the queue, this may take some time\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import numpy as np\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
    "import os\n",
    "import pyart\n",
    "import tarfile\n",
    "import tempfile\n",
    "import shutil\n",
    "from netCDF4 import num2date\n",
    "import json\n",
    "from time import strftime, sleep\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Globus Transfer                        [######### ] 349/353 files (ETA 00:00:02)"
     ]
    }
   ],
   "source": [
    "!adc_xfer -a /data/datastream/sgp/sgpxsaprsecI5.00/sgpxsaprsecI5.00.201807* /lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/unformatted/\n",
    "!adc_xfer -a /data/datastream/sgp/sgpxsaprsecI5.00/sgpxsaprsecI5.00.201808* /lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/unformatted/\n",
    "!adc_xfer -a /data/datastream/sgp/sgpxsaprsecI6.00/sgpxsaprsecI6.00.201807* /lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/unformatted/\n",
    "!adc_xfer -a /data/datastream/sgp/sgpxsaprsecI6.00/sgpxsaprsecI6.00.201808* /lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/unformatted/\n",
    "!adc_xfer -a /data/datastream/sgp/sgpxsaprsecI4.00/sgpxsaprsecI4.00.201807* /lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/unformatted/\n",
    "!adc_xfer -a /data/datastream/sgp/sgpxsaprsecI4.00/sgpxsaprsecI4.00.201808* /lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/unformatted/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = '/lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/'\n",
    "formatted_subdir = 'formatted'\n",
    "unformatted_subdir = 'unformatted'\n",
    "\n",
    "unformatted_dir = os.path.join(experiment_dir, unformatted_subdir)\n",
    "formatted_dir = os.path.join(experiment_dir, formatted_subdir)\n",
    "\n",
    "all_files = os.listdir(unformatted_dir)\n",
    "all_fqdn = [os.path.join(unformatted_dir, this_file) for this_file in all_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_tarfile(path_and_file, \n",
    "                   experiment_location='/lustre/or-hydra/cades-arm/proj-shared/scanning_experiment/formatted'):\n",
    "    def examine(fh_like):\n",
    "        radar = pyart.io.read(fh_like)\n",
    "        time_start = num2date(radar.time['data'][0], radar.time['units'])\n",
    "        time_end = num2date(radar.time['data'][-1], radar.time['units'])\n",
    "        stype = radar.scan_type\n",
    "        nsweeps = radar.nsweeps\n",
    "        tgates = float(radar.ngates*radar.nrays)\n",
    "        zdat = radar.fields['reflectivity']['data']\n",
    "        z0 = float(len(np.where(zdat > 0.)[0]))/tgates\n",
    "        z10 = float(len(np.where(zdat > 10.)[0]))/tgates\n",
    "        z40 = float(len(np.where(zdat > 40.)[0]))/tgates\n",
    "        rdict = {'time_start' : time_start,\n",
    "                'time_end' : time_end,\n",
    "                 'scan_type' : stype,\n",
    "                 'nsweeps' : nsweeps,\n",
    "                 'z0' : z0,\n",
    "                 'z10' : z10,\n",
    "                 'z40' : z40,\n",
    "                'expr' : radar.metadata['sigmet_task_name'].lower().strip().decode(\"utf-8\")}\n",
    "\n",
    "        return rdict\n",
    "\n",
    "    def site_from_name(name):\n",
    "        fullname = name.split('.')[0]\n",
    "        site = fullname[-2::]\n",
    "        return site\n",
    "\n",
    "    def file_formatter(stime, site, scanmode, base, expr):\n",
    "        #base/year/monthday\n",
    "        \n",
    "        mday = stime.strftime('%m%d')\n",
    "        odir = os.path.join(base,\n",
    "                            expr.lower(),\n",
    "                            scanmode,\n",
    "                            stime.strftime('%Y'),\n",
    "                            mday)\n",
    "        fname1 = 'sgpxsapr' + scanmode + site + stime.strftime('.%Y%m%d.%H%M%S')\n",
    "        return odir, fname1\n",
    "\n",
    "    top_level = os.path.split(experiment_location)[0]\n",
    "    tarobj = tarfile.open(path_and_file)\n",
    "    site = site_from_name(path_and_file)\n",
    "    members = tarobj.getmembers()\n",
    "    status = []\n",
    "    for member in members:\n",
    "        try:\n",
    "            radar_info = examine(tarobj.extractfile(member))\n",
    "            odir_radars, file_name_begin = file_formatter(radar_info['time_start'], \n",
    "                                                   site, \n",
    "                                                   radar_info['scan_type'],\n",
    "                                                   experiment_location,\n",
    "                                                   radar_info['expr'])\n",
    "\n",
    "            odir_json, file_name_begin = file_formatter(radar_info['time_start'], \n",
    "                                                   site, \n",
    "                                                   radar_info['scan_type'],\n",
    "                                                   os.path.join(top_level, 'summary'),\n",
    "                                                   radar_info['expr'])\n",
    "\n",
    "            try:\n",
    "                if not os.path.exists(odir_radars):\n",
    "                    os.makedirs(odir_radars)\n",
    "\n",
    "                if not os.path.exists(odir_json):\n",
    "                    os.makedirs(odir_json)\n",
    "            except: #just wait and try again..\n",
    "                sleep(1)\n",
    "                if not os.path.exists(odir_radars):\n",
    "                    os.makedirs(odir_radars)\n",
    "\n",
    "                if not os.path.exists(odir_json):\n",
    "                    os.makedirs(odir_json)\n",
    "\n",
    "            fullpath = os.path.join(odir_radars, file_name_begin+'.iris')\n",
    "\n",
    "            json_dict = {}\n",
    "            strconv_keys = ['z0', 'z10', 'z40', 'nsweeps']\n",
    "            for key in strconv_keys:\n",
    "                json_dict.update({key : str(radar_info[key])})\n",
    "\n",
    "            json_dict.update({'start_time' : radar_info['time_start'].strftime('%Y%m%d-%H:%M:%S'),\n",
    "                             'end_time' : radar_info['time_end'].strftime('%Y%m%d-%H:%M:%S')})\n",
    "\n",
    "            json_dict.update({'original_name' : member.name,\n",
    "                             'full_path' : fullpath})\n",
    "\n",
    "            r = json.dumps(json_dict)\n",
    "            loaded_r = json.loads(r)\n",
    "            with open(os.path.join(odir_json, file_name_begin+'.json'), 'w') as outfile:\n",
    "                json.dump(json_dict, outfile)\n",
    "\n",
    "            #The actuall writing\n",
    "            fh = tarobj.extractfile(member)\n",
    "\n",
    "            shutil.copyfileobj(fh, open(fullpath, 'wb'))\n",
    "            fh.close()\n",
    "            status.append(member.name+':OK')\n",
    "        except IndexError:\n",
    "            status.append(member.name+':NotOK')\n",
    "\n",
    "        \n",
    "    return status\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flist = manage_tarfile(all_fqdn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster = PBSCluster(name='dask-worker', memory='270GB', cores=36, processes=6, interface='ib0', queue='high_mem', project='arm',\n",
    "#                    walltime='00:30:00')#, job-extra=['-W group_list=cades-arm'])\n",
    "cluster = PBSCluster(processes = 18)\n",
    "cluster.scale(4)         # Ask for ten workers\n",
    "client = Client(cluster)  # Connect this local process to remote workers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```jobqueue:\n",
    "  pbs:\n",
    "    name: dask-worker\n",
    "    cores: 36\n",
    "    memory: 270GB\n",
    "    processes: 6\n",
    "    interface: ib0\n",
    "    local-directory: $localscratch\n",
    "    queue: high_mem # Can also select batch or gpu_ssd\n",
    "    project: arm\n",
    "    walltime: 00:30:00 #Adjust this to job size\n",
    "    job-extra: ['-W group_list=cades-arm']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47d4d2369964dd697efab2e984f3bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>PBSCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.23.216.81:42873\n",
       "  <li><b>Dashboard: </b><a href='http://10.23.216.81:50488/status' target='_blank'>http://10.23.216.81:50488/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>72</li>\n",
       "  <li><b>Cores: </b>144</li>\n",
       "  <li><b>Memory: </b>1.08 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.23.216.81:42873' processes=72 cores=144>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = client.map(manage_tarfile, all_fqdn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fde8232337e4603bb8e7fffc4e11f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scollis/anaconda3/envs/dask/lib/python3.6/site-packages/ipywidgets/widgets/widget.py:411: DeprecationWarning: Passing unrecoginized arguments to super(FloatProgress).__init__(height='10px').\n",
      "object.__init__() takes no parameters\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super(Widget, self).__init__(**kwargs)\n",
      "/home/scollis/anaconda3/envs/dask/lib/python3.6/site-packages/ipywidgets/widgets/widget.py:411: DeprecationWarning: Passing unrecoginized arguments to super(HTML).__init__(width='140px').\n",
      "object.__init__() takes no parameters\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super(Widget, self).__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "progress(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18103\n",
      "18103\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "my_data = client.gather(future)\n",
    "flat_list = [item for sublist in my_data for item in sublist]\n",
    "print(len(flat_list))\n",
    "succeeded = 0\n",
    "failed = 0\n",
    "ff = []\n",
    "SE_good = []\n",
    "for item in flat_list:\n",
    "    if 'NotOK' in item:\n",
    "        failed +=  1\n",
    "        ff.append(item)\n",
    "    else:\n",
    "        succeeded += 1\n",
    "        if 'XSE'in item:\n",
    "            SE_good.append(item)\n",
    "\n",
    "print(succeeded)\n",
    "print(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180623 :  0\n",
      "180624 :  0\n",
      "180625 :  0\n",
      "180626 :  0\n",
      "180627 :  0\n",
      "180628 :  0\n",
      "180629 :  0\n",
      "180630 :  0\n",
      "180701 :  0\n",
      "180702 :  0\n",
      "180703 :  0\n",
      "180704 :  0\n",
      "180705 :  0\n",
      "180706 :  0\n",
      "180707 :  0\n",
      "180708 :  0\n",
      "180709 :  0\n",
      "180710 :  0\n",
      "180711 :  0\n",
      "180712 :  0\n",
      "180713 :  0\n",
      "180714 :  0\n",
      "180715 :  0\n",
      "180716 :  0\n",
      "180717 :  0\n",
      "180718 :  0\n",
      "180719 :  0\n",
      "180720 :  0\n",
      "180721 :  0\n",
      "180722 :  0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "tstart = datetime.datetime(2018, 6, 23)\n",
    "strlist = []\n",
    "for i in range(30):\n",
    "    dt = timedelta(days=i)\n",
    "    datetm = (tstart + dt).strftime('%y%m%d')\n",
    "    strlist.append(datetm)\n",
    "\n",
    "\n",
    "for datestris in  strlist:\n",
    "    nbad = 0\n",
    "    for itis in ff:\n",
    "        if datestris in itis:\n",
    "            nbad += 1\n",
    "    print(datestris, ': ', nbad )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
